# Azure Open AI: Gerenciando Limites de Capacidade e Quota com Bicep

## Introdução

Estamos atualmente em um período de "corrida do ouro" da IA. O mundo não consegue ter o suficiente. Uma consequência disso é que a racionamento é necessário. É como o final da Segunda Guerra Mundial, mas com GPUs. Embora isso tenha seus aspectos positivos — significando que não podemos simplesmente criar tantos recursos quanto quisermos — também é negativo pelo mesmo motivo.

Se você está utilizando os recursos de Open AI da Azure para atender às suas necessidades de IA, deve estar ciente de que existem limites conhecidos como "quotas". Se você deseja controlar quantos recursos está utilizando, precisará controlar a capacidade de suas implementações. Isso é possível com Bicep.

Este post surgiu de uma questão no GitHub sobre o tema, onde as pessoas enfrentavam a mensagem de que a capacidade deveria ser nula para implementações padrão ao tentarem realizar uma implementação. Na época, havia pouca documentação sobre como lidar com isso. Desde então, as coisas melhoraram, mas pensei que seria útil ter um post sobre o assunto.

## Visualizando Limites de Capacidade e Quota no Azure Open AI Studio

Se você olhar para o Azure Open AI Studio, notará uma seção "Quotas":

- Você verá que temos duas implementações do GPT-35-Turbo em nossa assinatura.
- Ambas contribuem para um limite total de 360K TPM.
- Se tentarmos implantar recursos e o total de capacidade geral exceder isso, nossa implantação falhará.

Diante disso, precisamos ser capazes de controlar a capacidade de nossas implementações, e isso é viável com Bicep.

## Controlando Limites de Capacidade e Quota com Bicep

Considere o seguinte código do `account-deployments.bicep`:

```bicep
@description('Nome do recurso Cognitive Services')
param cognitiveServicesName string

@description('Nome do recurso de implantação.')
param deploymentName string

@description('Formato do modelo de implantação.')
param format string

@description('Nome do modelo de implantação.')
param name string

@description('Versão do modelo de implantação.')
param version string = '1'

@description('O nome da política RAI.')
param raiPolicyName string = 'Default'

@allowed([
  'NoAutoUpgrade'
  'OnceCurrentVersionExpired'
  'OnceNewDefaultVersionAvailable'
])

@description('Opção de upgrade da versão do modelo de implantação. Veja https://learn.microsoft.com/en-us/azure/templates/microsoft.cognitiveservices/2023-05-01/accounts/deployments?pivots=deployment-language-bicep#deploymentproperties')
param versionUpgradeOption string = 'OnceNewDefaultVersionAvailable'

@description('''SKU de implantações veja: https://learn.microsoft.com/en-us/azure/templates/microsoft.cognitiveservices/2023-05-01/accounts/deployments?pivots=deployment-language-bicep#sku 
ex: sku: {
  name: 'Standard'
  capacity: 10
}
''')
param sku object

resource cog 'Microsoft.CognitiveServices/accounts@2023-05-01' existing = {
  name: cognitiveServicesName
}

resource deployment 'Microsoft.CognitiveServices/accounts/deployments@2023-05-01' = {
  name: deploymentName
  parent: cog
  sku: sku
  properties: {
    model: {
      format: format
      name: name
      version: version
    }
    raiPolicyName: raiPolicyName
    versionUpgradeOption: versionUpgradeOption
  }
}

output deploymentName string = deployment.name
output deploymentResourceId string = deployment.id
```

Podemos usar isso para implantar...

```bicep
var cognitiveServicesDeployments = [
  {
    name: 'OpenAi-gpt-35-turbo'
    shortName: 'gpt35t'
    model: {
      format: 'OpenAI'
      name: 'gpt-35-turbo'
      version: '0301'
    }
    sku: {
      name: 'Standard'
      capacity: repositoryBranch == 'refs/heads/main' ? 100 : 10 // a capacidade em milhares de TPM
    }
  }
]
```

## Conclusão

Atualmente, estamos implementando apenas uma única implantação de conta em nosso array, mas fazemos isso dessa maneira, pois não é incomum implementar múltiplas implementações juntas. Nota também a parte do SKU onde definimos uma capacidade maior para nossas implementações de branch de funcionalidades do que para as da branch principal.

Isso demonstra nosso próprio uso, pelo qual implementamos uma capacidade menor para nossas branches de funcionalidades para que possamos testar, e depois uma capacidade maior para as implantações de nossos branches principais. Significativamente, estamos controlando a capacidade de nossas implementações. A maneira como você decide a capacidade de suas implantações é com você, mas o acima demonstra como você pode fazer isso com Bicep e manter-se dentro dos limites de quota.